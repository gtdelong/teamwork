{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from itertools import combinations \n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from math import comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.0387992000032682 seconds or 0.0006466533333878033 minutes to read in data and modify table\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "\n",
    "discharges_test_file = '../data/discharges_test.csv'\n",
    "notes_test_file = '../data/notes_test.csv'\n",
    "\n",
    "# discharges_test_file = '../data/discharges_w_disposition_abdul_test.csv'\n",
    "# notes_test_file = '../data/notes_w_disposition_abdul_test.csv'\n",
    "\n",
    "# discharges_test_file = '../data/discharges_w_datetime.csv'\n",
    "# notes_test_file = '../data/notes_w_datetime.csv'\n",
    "\n",
    "discharge_table = pd.read_csv(discharges_test_file, parse_dates=['arrive_date','discharge_date'])\n",
    "notes_table = pd.read_csv(notes_test_file, parse_dates=['date'])\n",
    "notes_table.rename(columns = {'discharge_id':'id'}, inplace = True)\n",
    "\n",
    "# authors who wrote notes within 48 hours of arrival date are in index team for that patient\n",
    "INDEX_DELTA = np.timedelta64(2, 'D')\n",
    "# notes written within previous 90 days are considered when calculating collaborative experience\n",
    "TEAMWORK_DELTA = np.timedelta64(90, 'D')\n",
    "\n",
    "# match in admission datetime indexing on visit id from discharge table\n",
    "notes_table = notes_table.merge(discharge_table, on='id', how='right')\n",
    "\n",
    "# create new column for normalized date by ignoring time of day\n",
    "notes_table['norm_arrive_date'] = notes_table['arrive_date'].astype('datetime64[D]')\n",
    "notes_table['norm_note_date'] = notes_table['date'].astype('datetime64[D]')\n",
    "\n",
    "notes_table.drop_duplicates(['norm_note_date','dr','id'], keep=\"first\", inplace=True)\n",
    "\n",
    "notes_table.sort_values('arrive_date', inplace=True)\n",
    "FIRST_DATE = notes_table['arrive_date'].iloc[0]\n",
    "\n",
    "# add indicator column for whether the note author is in the index team\n",
    "notes_table['is_in_team'] = notes_table[\"date\"] - notes_table[\"arrive_date\"] <= INDEX_DELTA\n",
    "\n",
    "stop_time = time.perf_counter()\n",
    "print(f\"It took {stop_time - start_time} seconds or {(stop_time - start_time) / 60} minutes to read in data and modify table\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dr</th>\n",
       "      <th>date</th>\n",
       "      <th>patient</th>\n",
       "      <th>arrive_date</th>\n",
       "      <th>discharge_date</th>\n",
       "      <th>disposition</th>\n",
       "      <th>age</th>\n",
       "      <th>norm_arrive_date</th>\n",
       "      <th>norm_note_date</th>\n",
       "      <th>is_in_team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Brad Palmer</td>\n",
       "      <td>2019-01-01 19:15:00</td>\n",
       "      <td>patient1</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Albert Romero</td>\n",
       "      <td>2019-01-24 10:19:00</td>\n",
       "      <td>patient2</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Margie Meyer</td>\n",
       "      <td>2019-01-24 17:09:00</td>\n",
       "      <td>patient2</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Evan Frazier</td>\n",
       "      <td>2019-01-24 16:48:00</td>\n",
       "      <td>patient2</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Myrtle George</td>\n",
       "      <td>2019-01-24 13:41:00</td>\n",
       "      <td>patient2</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id             dr                date   patient arrive_date discharge_date  \\\n",
       "0   0    Brad Palmer 2019-01-01 19:15:00  patient1  2019-01-01     2019-01-01   \n",
       "1   1  Albert Romero 2019-01-24 10:19:00  patient2  2019-01-24     2019-01-24   \n",
       "2   1   Margie Meyer 2019-01-24 17:09:00  patient2  2019-01-24     2019-01-24   \n",
       "3   1   Evan Frazier 2019-01-24 16:48:00  patient2  2019-01-24     2019-01-24   \n",
       "4   1  Myrtle George 2019-01-24 13:41:00  patient2  2019-01-24     2019-01-24   \n",
       "\n",
       "   disposition  age norm_arrive_date norm_note_date  is_in_team  \n",
       "0            1   75       2019-01-01     2019-01-01        True  \n",
       "1            0   68       2019-01-24     2019-01-24        True  \n",
       "2            0   68       2019-01-24     2019-01-24        True  \n",
       "3            0   68       2019-01-24     2019-01-24        True  \n",
       "4            0   68       2019-01-24     2019-01-24        True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.026982399984262884 seconds or 0.0004497066664043814 minutes to self join and get edges table\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "\n",
    "# do self join on discharge id and normalized note date to get table of edges\n",
    "edges_table = notes_table.merge(notes_table[['dr','id','is_in_team','norm_note_date']], how='inner', on=['id','norm_note_date'])\n",
    "# remove edges with the same name twice or with authors in reverse order\n",
    "edges_table = edges_table[edges_table['dr_x'] < edges_table['dr_y']]\n",
    "edges_table['edge'] = edges_table['dr_x'] + edges_table['dr_y']\n",
    "\n",
    "# might be able to remove this line, need to discuss\n",
    "edges_table['is_in_team'] = edges_table['is_in_team_x'] & edges_table['is_in_team_y']\n",
    "# add column indicating whether there are 90 days prior to arrive date. if not, don't count as index team\n",
    "edges_table['is_after_delta'] = edges_table[\"arrive_date\"] > (FIRST_DATE + TEAMWORK_DELTA)\n",
    "\n",
    "stop_time = time.perf_counter()\n",
    "print(f\"It took {stop_time - start_time} seconds or {(stop_time - start_time) / 60} minutes to self join and get edges table\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.025414600007934496 seconds or 0.00042357666679890824 minutes to self join and get edges table\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "\n",
    "# do self join on discharge id get table of team edges\n",
    "team_table = notes_table.merge(notes_table[['dr','id','is_in_team','norm_note_date']], how='inner', on='id')\n",
    "# remove edges with the same name twice or with authors in reverse order\n",
    "team_table = team_table[team_table['dr_x'] < team_table['dr_y']]\n",
    "team_table['edge'] = team_table['dr_x'] + team_table['dr_y']\n",
    "\n",
    "# might be able to remove this line, need to discuss\n",
    "team_table['is_in_team'] = team_table['is_in_team_x'] & team_table['is_in_team_y']\n",
    "# add column indicating whether there are 90 days prior to arrive date. if not, don't count as index team\n",
    "team_table['is_after_delta'] = team_table[\"arrive_date\"] > (FIRST_DATE + TEAMWORK_DELTA)\n",
    "\n",
    "team_table = team_table[team_table['is_in_team'] & team_table['is_after_delta']]\n",
    "\n",
    "stop_time = time.perf_counter()\n",
    "print(f\"It took {stop_time - start_time} seconds or {(stop_time - start_time) / 60} minutes to self join and get edges table\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_for_row(g, visit_id, team):\n",
    "    data = {}\n",
    "    data['discharge_id'] = visit_id\n",
    "    \n",
    "    ''' Clustering coefficient of all nodes (in a dictionary) '''\n",
    "    clustering_coefficient = nx.clustering(g, weight='weight')\n",
    "    \n",
    "    ''' Average clustering coefficient with divide-by-zero check '''\n",
    "    clust_sum = sum(clustering_coefficient.values())\n",
    "    clust_len = len(clustering_coefficient)\n",
    "        \n",
    "    data['avg_clust'] = clust_sum / clust_len if clust_len > 0 else 0 \n",
    "    \n",
    "    data['sum_clust'] = clust_sum\n",
    "    data['team_size'] = len(team)\n",
    "    potential_edges = comb(len(team),2)\n",
    "    data['potential_edges'] = potential_edges\n",
    "    data['team_edge_size'] = g.number_of_edges()\n",
    "    \n",
    "    experience = g.size(weight='weight') #Experience as sum of weights\n",
    "    data['cumulative_experience'] = experience - data['team_edge_size']\n",
    "    data['avg_cumulative_experience'] = data['cumulative_experience'] / potential_edges if data['team_size'] > 0 else 0\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/std.py:699: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "Dictionary Progress Bar!: 100%|██████████| 33/33 [00:00<00:00, 4066.88it/s]\n",
      "Dictionary Progress Bar!: 100%|██████████| 28/28 [00:00<00:00, 4777.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.029244600009405985 seconds or 0.00048741000015676644 minutes to build dictionaries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# map discharge id to list of edges\n",
    "discharge_id_to_edges_dict = dict()\n",
    "# map edge to list of dates when note authors collaborated\n",
    "edge_to_date_dict = dict()\n",
    "# map discharge id to list of team members\n",
    "discharge_id_to_team_dict = dict()\n",
    "\n",
    "def add_to_team_dict(edge_record):\n",
    "    edge_tup = (edge_record['dr_x'], edge_record['dr_y'])\n",
    "    # store edge, individual note author names, and arrive date in list item\n",
    "    edge_list_item = (edge_record['edge'], edge_tup, edge_record['norm_arrive_date'])\n",
    "    discharge_id_to_edges_dict.setdefault(edge_record['id'],[]).append(edge_list_item)\n",
    "    discharge_id_to_team_dict.setdefault(edge_record['id'],set()).update(edge_tup)\n",
    "\n",
    "def add_edge_to_dict(edge_record):\n",
    "    edge_to_date_dict.setdefault(edge_record['edge'],[]).append(edge_record['norm_note_date'])\n",
    "    \n",
    "tqdm.pandas(desc=\"Dictionary Progress Bar!\")\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "# edges_table.apply(add_edge_to_dict, axis='columns')\n",
    "\n",
    "# team_table.apply(add_to_team_dict, axis='columns')\n",
    "\n",
    "edges_table.progress_apply(add_edge_to_dict, axis='columns')\n",
    "\n",
    "team_table.progress_apply(add_to_team_dict, axis='columns')\n",
    "    \n",
    "stop_time = time.perf_counter()\n",
    "print(f\"It took {stop_time - start_time} seconds or {(stop_time - start_time) / 60} minutes to build dictionaries\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 139.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.011213899997528642 seconds or 0.00018689833329214403 minutes to create graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "experience_data_list = []\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "for discharge_id, edge_items in tqdm(discharge_id_to_edges_dict.items()):\n",
    "    edge_list = []\n",
    "    for edge_item in edge_items:\n",
    "        edge = edge_item[0]\n",
    "        if edge not in edge_to_date_dict: continue\n",
    "        (dr_x,dr_y) = edge_item[1]\n",
    "        arrive_date = edge_item[2]\n",
    "        weight = len([note_day for note_day in edge_to_date_dict[edge] \n",
    "                      if note_day < arrive_date and note_day >= arrive_date - TEAMWORK_DELTA])\n",
    "        if(weight < 1): continue \n",
    "        edge_list.append({'source':dr_x,'target':dr_y,'weight':weight})\n",
    "    edge_df = pd.DataFrame(edge_list, columns = ['source', 'target', 'weight'])\n",
    "    g = nx.from_pandas_edgelist(edge_df, source='source', target='target',edge_attr='weight')\n",
    "    team = discharge_id_to_team_dict[discharge_id]\n",
    "    experience_data_list.append(get_output_for_row(g, discharge_id, team))\n",
    "        \n",
    "stop_time = time.perf_counter()\n",
    "print(f\"It took {stop_time - start_time} seconds or {(stop_time - start_time) / 60} minutes to create graphs\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discharge_id</th>\n",
       "      <th>avg_clust</th>\n",
       "      <th>cumulative_experience</th>\n",
       "      <th>avg_cumulative_experience</th>\n",
       "      <th>team_edge_size</th>\n",
       "      <th>team_size</th>\n",
       "      <th>potential_edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.677976</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discharge_id  avg_clust  cumulative_experience  avg_cumulative_experience  \\\n",
       "0             6   0.677976                    6.0                   0.214286   \n",
       "\n",
       "   team_edge_size  team_size  potential_edges  \n",
       "0              15          8               28  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['discharge_id',\n",
    "        'avg_clust',\n",
    "        'cumulative_experience',\n",
    "        'avg_cumulative_experience',\n",
    "        'team_edge_size',\n",
    "           'team_size',\n",
    "           'potential_edges'\n",
    "          ]\n",
    "\n",
    "# experience_df = pd.DataFrame(experience_data_list, columns=columns).drop_duplicates()\n",
    "experience_df = pd.DataFrame(experience_data_list, columns=columns)\n",
    "experience_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Grant DeLongMargie Meyer', ('Grant DeLong', 'Margie Meyer'), Timestamp('2019-04-15 00:00:00')), ('Grant DeLongMyrtle George', ('Grant DeLong', 'Myrtle George'), Timestamp('2019-04-15 00:00:00')), ('Grant DeLongVictoria Washington', ('Grant DeLong', 'Victoria Washington'), Timestamp('2019-04-15 00:00:00')), ('Grant DeLongNeil Mitchell', ('Grant DeLong', 'Neil Mitchell'), Timestamp('2019-04-15 00:00:00')), ('Grant DeLongHenry Philofsky', ('Grant DeLong', 'Henry Philofsky'), Timestamp('2019-04-15 00:00:00')), ('Albert RomeroGrant DeLong', ('Albert Romero', 'Grant DeLong'), Timestamp('2019-04-15 00:00:00')), ('Albert RomeroMargie Meyer', ('Albert Romero', 'Margie Meyer'), Timestamp('2019-04-15 00:00:00')), ('Albert RomeroEvan Frazier', ('Albert Romero', 'Evan Frazier'), Timestamp('2019-04-15 00:00:00')), ('Albert RomeroMyrtle George', ('Albert Romero', 'Myrtle George'), Timestamp('2019-04-15 00:00:00')), ('Albert RomeroVictoria Washington', ('Albert Romero', 'Victoria Washington'), Timestamp('2019-04-15 00:00:00')), ('Albert RomeroNeil Mitchell', ('Albert Romero', 'Neil Mitchell'), Timestamp('2019-04-15 00:00:00')), ('Albert RomeroHenry Philofsky', ('Albert Romero', 'Henry Philofsky'), Timestamp('2019-04-15 00:00:00')), ('Margie MeyerMyrtle George', ('Margie Meyer', 'Myrtle George'), Timestamp('2019-04-15 00:00:00')), ('Margie MeyerVictoria Washington', ('Margie Meyer', 'Victoria Washington'), Timestamp('2019-04-15 00:00:00')), ('Margie MeyerNeil Mitchell', ('Margie Meyer', 'Neil Mitchell'), Timestamp('2019-04-15 00:00:00')), ('Evan FrazierGrant DeLong', ('Evan Frazier', 'Grant DeLong'), Timestamp('2019-04-15 00:00:00')), ('Evan FrazierMargie Meyer', ('Evan Frazier', 'Margie Meyer'), Timestamp('2019-04-15 00:00:00')), ('Evan FrazierMyrtle George', ('Evan Frazier', 'Myrtle George'), Timestamp('2019-04-15 00:00:00')), ('Evan FrazierVictoria Washington', ('Evan Frazier', 'Victoria Washington'), Timestamp('2019-04-15 00:00:00')), ('Evan FrazierNeil Mitchell', ('Evan Frazier', 'Neil Mitchell'), Timestamp('2019-04-15 00:00:00')), ('Evan FrazierHenry Philofsky', ('Evan Frazier', 'Henry Philofsky'), Timestamp('2019-04-15 00:00:00')), ('Myrtle GeorgeVictoria Washington', ('Myrtle George', 'Victoria Washington'), Timestamp('2019-04-15 00:00:00')), ('Myrtle GeorgeNeil Mitchell', ('Myrtle George', 'Neil Mitchell'), Timestamp('2019-04-15 00:00:00')), ('Neil MitchellVictoria Washington', ('Neil Mitchell', 'Victoria Washington'), Timestamp('2019-04-15 00:00:00')), ('Henry PhilofskyMargie Meyer', ('Henry Philofsky', 'Margie Meyer'), Timestamp('2019-04-15 00:00:00')), ('Henry PhilofskyMyrtle George', ('Henry Philofsky', 'Myrtle George'), Timestamp('2019-04-15 00:00:00')), ('Henry PhilofskyVictoria Washington', ('Henry Philofsky', 'Victoria Washington'), Timestamp('2019-04-15 00:00:00')), ('Henry PhilofskyNeil Mitchell', ('Henry Philofsky', 'Neil Mitchell'), Timestamp('2019-04-15 00:00:00'))]\n",
      "{'Margie Meyer', 'Albert Romero', 'Grant DeLong', 'Evan Frazier', 'Neil Mitchell', 'Victoria Washington', 'Myrtle George', 'Henry Philofsky'}\n"
     ]
    }
   ],
   "source": [
    "print(discharge_id_to_edges_dict[6])\n",
    "print(discharge_id_to_team_dict[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This code does not work but playing around with an easy API for the library'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''This code does not work but playing around with an easy API for the library'''\n",
    "\n",
    "# column_names = {\n",
    "#     \"visit_id\": \"discharge_id\",\n",
    "#     \"admission_date\": \"arrive_date\",\n",
    "#     \"note_author\": \"dr\",\n",
    "#     \"note_date\": \"date\"\n",
    "# }\n",
    "\n",
    "# EXPERIENCE_WINDOW = 90\n",
    "# TEAM_WINDOW = 2\n",
    "\n",
    "# study = TeamWorkStudy(notes_csv_file, EXPERIENCE_WINDOW,TEAM_WINDOW, column_names=column_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5, 8}\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myset = set([1,2,3])\n",
    "myset.add(1)\n",
    "myset.add(4)\n",
    "myset.update((2,5,8))\n",
    "print(myset)\n",
    "print(len(myset))\n",
    "\n",
    "from math import comb\n",
    "comb(4,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date' 'value' 'another' 'another_column']\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.DataFrame({'date': ['3/10/2000', '3/11/2000', '3/12/2000'],\n",
    "                   'value': [2, 3, 4],\n",
    "                       'another': [6,7,8]})\n",
    "def add_column(df):\n",
    "    df['another_column'] = [7,8,9]\n",
    "add_column(test_df)\n",
    "print(test_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "{1, 2, 3}\n",
      "1\n",
      "4\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = {'values':'value', 'datetime':'custdate'}\n",
    "defcols = {'datetime':'date','values':'value','hello':[1,2,3], 'goodbye':{1,2,3}}\n",
    "mycols = {**defcols,**cols}\n",
    "def take_params(**cols):\n",
    "    print(cols['hello'])\n",
    "take_params(**mycols)\n",
    "\n",
    "_,v,_,gb = [*mycols.values()]\n",
    "print(gb)  \n",
    "\n",
    "def print_val(v):\n",
    "    print(v)\n",
    "    \n",
    "list(map(print_val, [1,4,5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-05-26 20:10:16.799886 ForkPoolWorker-2 running for r := 13\n",
      "2021-05-26 20:10:16.799987 ForkPoolWorker-3 running for r := 20\n",
      "2021-05-26 20:10:16.799884 ForkPoolWorker-1 running for r := 11\n",
      "2021-05-26 20:10:16.800133 ForkPoolWorker-4 running for r := 20\n",
      "\n",
      "\n",
      "\n",
      "cpu count: 8\n",
      "2021-05-26 20:10:16.797450 MainProcess waiting\n",
      "2021-05-26 20:10:22.277877 ForkPoolWorker-1 exiting with sum of 458334570834992500825\n",
      "in callback: 458334570834992500825\n",
      "2021-05-26 20:10:23.363070 ForkPoolWorker-2 exiting with sum of 541668454169537501716\n",
      "in callback: 541668454169537501716\n",
      "2021-05-26 20:10:25.930157 ForkPoolWorker-4 exiting with sum of 833337833344750010830\n",
      "2021-05-26 20:10:26.090395 ForkPoolWorker-3 exiting with sum of 833337833344750010830\n",
      "in callback: 833337833344750010830\n",
      "in callback: 833337833344750010830\n",
      "2021-05-26 20:10:26.099596 MainProcess out of with block\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool, Process, connection, current_process, cpu_count\n",
    "from random import randint\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def run(i):\n",
    "    sleep_time = randint(2,10)\n",
    "    sleep(sleep_time)\n",
    "    print(f\"{datetime.now()} {current_process().name} exiting with arg {i} after sleeping for {sleep_time}\")\n",
    "\n",
    "def cpu_bound(numbers, r):\n",
    "    print(f\"\\n{datetime.now()} {current_process().name} running for r := {r}\")\n",
    "    thesum = sum(sum(i * i for i in range(number)) for number in numbers)\n",
    "    print(f\"{datetime.now()} {current_process().name} exiting with sum of {thesum}\")\n",
    "    return thesum\n",
    "\n",
    "def get_numbers(r):\n",
    "    return [5_000_000 + i for i in range(r)]\n",
    "\n",
    "def print_res(res):\n",
    "    print(f'in callback: {res}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(cpu_count()) as pool:\n",
    "        print(f'cpu count: {cpu_count()}')\n",
    "#         pool = [Process(target=cpu_bound,args=(get_numbers(r := randint(10,20)), r)) for _ in range(4)]\n",
    "        print(f\"{datetime.now()} {current_process().name} waiting\")\n",
    "        multiple_results = [pool.apply_async(cpu_bound, args=(get_numbers(r := randint(10,20)), r), callback=print_res) for _ in range(4)]\n",
    "        [res.get() for res in multiple_results]\n",
    "\n",
    "    print(f\"{datetime.now()} {current_process().name} out of with block\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
