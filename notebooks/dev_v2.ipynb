{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from itertools import combinations \n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.04005100001813844 seconds or 0.000667516666968974 minutes to read in data and modify table\n",
      "   id             dr       date   patient arrive_date discharge_date  \\\n",
      "0   0    Brad Palmer 2019-01-01  patient1  2019-01-01     2019-01-01   \n",
      "1   1  Albert Romero 2019-01-24  patient2  2019-01-24     2019-01-24   \n",
      "2   1   Margie Meyer 2019-01-24  patient2  2019-01-24     2019-01-24   \n",
      "3   1   Evan Frazier 2019-01-24  patient2  2019-01-24     2019-01-24   \n",
      "4   1  Myrtle George 2019-01-24  patient2  2019-01-24     2019-01-24   \n",
      "\n",
      "   disposition  age norm_arrive_date norm_note_date  is_in_team  \n",
      "0            1   75       2019-01-01     2019-01-01        True  \n",
      "1            0   68       2019-01-24     2019-01-24        True  \n",
      "2            0   68       2019-01-24     2019-01-24        True  \n",
      "3            0   68       2019-01-24     2019-01-24        True  \n",
      "4            0   68       2019-01-24     2019-01-24        True  \n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "\n",
    "discharges_test_file = '../data/discharges_test.csv'\n",
    "notes_test_file = '../data/notes_test.csv'\n",
    "\n",
    "discharge_table = pd.read_csv(discharges_test_file, parse_dates=['arrive_date','discharge_date'])\n",
    "notes_table = pd.read_csv(notes_test_file, parse_dates=['date'])\n",
    "notes_table.rename(columns = {'discharge_id':'id'}, inplace = True)\n",
    "\n",
    "# authors who wrote notes within 48 hours of arrival date are in index team for that patient\n",
    "INDEX_DELTA = np.timedelta64(2, 'D')\n",
    "# notes written within previous 90 days are considered when calculating collaborative experience\n",
    "TEAMWORK_DELTA = np.timedelta64(90, 'D')\n",
    "\n",
    "# match in admission datetime indexing on visit id from discharge table\n",
    "notes_table = notes_table.merge(discharge_table, on='id', how='right')\n",
    "\n",
    "# create new column for normalized date by ignoring time of day\n",
    "notes_table['norm_arrive_date'] = notes_table['arrive_date'].astype('datetime64[D]')\n",
    "notes_table['norm_note_date'] = notes_table['date'].astype('datetime64[D]')\n",
    "\n",
    "notes_table.drop_duplicates(['norm_note_date','dr','id'], keep=\"first\", inplace=True)\n",
    "\n",
    "notes_table.sort_values('arrive_date', inplace=True)\n",
    "FIRST_DATE = notes_table['arrive_date'].iloc[0]\n",
    "\n",
    "# add indicator column for whether the note author is in the index team\n",
    "notes_table['is_in_team'] = notes_table[\"date\"] - notes_table[\"arrive_date\"] <= INDEX_DELTA\n",
    "\n",
    "stop_time = time.perf_counter()\n",
    "print(f\"It took {stop_time - start_time} seconds or {(stop_time - start_time) / 60} minutes to read in data and modify table\")   \n",
    "\n",
    "print(notes_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.03155489999335259 seconds or 0.0005259149998892099 minutes to self join and get edges table\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "\n",
    "# do self join on discharge id and normalized note date to get table of edges\n",
    "edges_table = notes_table.merge(notes_table[['dr','id','is_in_team','norm_note_date']], how='inner', on=['id','norm_note_date'])\n",
    "# remove edges with the same name twice or with authors in reverse order\n",
    "edges_table = edges_table[edges_table['dr_x'] < edges_table['dr_y']]\n",
    "edges_table['edge'] = edges_table['dr_x'] + edges_table['dr_y']\n",
    "\n",
    "# might be able to remove this line, need to discuss\n",
    "edges_table['is_in_team'] = edges_table['is_in_team_x'] & edges_table['is_in_team_y']\n",
    "# add column indicating whether there are 90 days prior to arrive date. if not, don't count as index team\n",
    "edges_table['is_after_delta'] = edges_table[\"arrive_date\"] > (FIRST_DATE + TEAMWORK_DELTA)\n",
    "\n",
    "stop_time = time.perf_counter()\n",
    "print(f\"It took {stop_time - start_time} seconds or {(stop_time - start_time) / 60} minutes to self join and get edges table\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.02238260000012815 seconds or 0.0003730433333354692 minutes to self join and get edges table\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "\n",
    "# do self join on discharge id get table of team edges\n",
    "team_table = notes_table.merge(notes_table[['dr','id','is_in_team','norm_note_date']], how='inner', on='id')\n",
    "# remove edges with the same name twice or with authors in reverse order\n",
    "team_table = team_table[team_table['dr_x'] < team_table['dr_y']]\n",
    "team_table['edge'] = team_table['dr_x'] + team_table['dr_y']\n",
    "\n",
    "# might be able to remove this line, need to discuss\n",
    "team_table['is_in_team'] = team_table['is_in_team_x'] & team_table['is_in_team_y']\n",
    "# add column indicating whether there are 90 days prior to arrive date. if not, don't count as index team\n",
    "team_table['is_after_delta'] = team_table[\"arrive_date\"] > (FIRST_DATE + TEAMWORK_DELTA)\n",
    "\n",
    "team_table = team_table[team_table['is_in_team'] & team_table['is_after_delta']]\n",
    "\n",
    "stop_time = time.perf_counter()\n",
    "print(f\"It took {stop_time - start_time} seconds or {(stop_time - start_time) / 60} minutes to self join and get edges table\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_for_row(g, visit_id):\n",
    "    data = {}\n",
    "    data['discharge_id'] = visit_id\n",
    "    \n",
    "    ''' Clustering coefficient of all nodes (in a dictionary) '''\n",
    "    clustering_coefficient = nx.clustering(g, weight='weight')\n",
    "    \n",
    "    ''' Average clustering coefficient with divide-by-zero check '''\n",
    "    clust_sum = sum(clustering_coefficient.values())\n",
    "    clust_len = len(clustering_coefficient)\n",
    "        \n",
    "    data['avg_clust'] = clust_sum / clust_len if clust_len > 0 else 0 \n",
    "    \n",
    "    data['sum_clust'] = clust_sum\n",
    "    data['team_size'] = g.number_of_nodes()\n",
    "    data['team_edge_size'] = g.number_of_edges()\n",
    "    \n",
    "    experience = g.size(weight='weight') #Experience as sum of weights\n",
    "    data['cumulative_experience'] = experience - data['team_edge_size']\n",
    "    data['avg_cumulative_experience'] = data['cumulative_experience'] / data['team_size'] if data['team_size'] > 0 else 0\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/std.py:699: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "Dictionary Progress Bar!: 100%|██████████| 28/28 [00:00<00:00, 2515.54it/s]\n",
      "Dictionary Progress Bar!: 100%|██████████| 21/21 [00:00<00:00, 4070.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.032036000047810376 seconds or 0.000533933334130173 minutes to build dictionaries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# map discharge id to list of edges\n",
    "discharge_id_to_edges_dict = dict()\n",
    "# map edge to list of dates when note authors collaborated\n",
    "edge_to_date_dict = dict()\n",
    "\n",
    "def add_to_team_dict(edge_record):\n",
    "    edge_tup = (edge_record['dr_x'], edge_record['dr_y'])\n",
    "    # store edge, individual note author names, and arrive date in list item\n",
    "    edge_list_item = (edge_record['edge'], edge_tup, edge_record['norm_arrive_date'])\n",
    "    discharge_id_to_edges_dict.setdefault(edge_record['id'],[]).append(edge_list_item)\n",
    "\n",
    "def add_edge_to_dict(edge_record):\n",
    "    edge_to_date_dict.setdefault(edge_record['edge'],[]).append(edge_record['norm_note_date'])\n",
    "    \n",
    "tqdm.pandas(desc=\"Dictionary Progress Bar!\")\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "# edges_table.apply(add_edge_to_dict, axis='columns')\n",
    "\n",
    "# team_table.apply(add_to_team_dict, axis='columns')\n",
    "\n",
    "edges_table.progress_apply(add_edge_to_dict, axis='columns')\n",
    "\n",
    "team_table.progress_apply(add_to_team_dict, axis='columns')\n",
    "    \n",
    "stop_time = time.perf_counter()\n",
    "print(f\"It took {stop_time - start_time} seconds or {(stop_time - start_time) / 60} minutes to build dictionaries\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 182.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.012031399994157255 seconds or 0.00020052333323595424 minutes to create graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "experience_data_list = []\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "for discharge_id, edge_items in tqdm(discharge_id_to_edges_dict.items()):\n",
    "    edge_list = []\n",
    "    for edge_item in edge_items:\n",
    "        edge = edge_item[0]\n",
    "        if edge not in edge_to_date_dict: continue\n",
    "        (dr_x,dr_y) = edge_item[1]\n",
    "        arrive_date = edge_item[2]\n",
    "        weight = len([note_day for note_day in edge_to_date_dict[edge] \n",
    "                      if note_day < arrive_date and note_day >= arrive_date - TEAMWORK_DELTA])\n",
    "        if(weight < 1): continue \n",
    "        edge_list.append({'source':dr_x,'target':dr_y,'weight':weight})\n",
    "    edge_df = pd.DataFrame(edge_list, columns = ['source', 'target', 'weight'])\n",
    "    g = nx.from_pandas_edgelist(edge_df, source='source', target='target',edge_attr='weight')\n",
    "    experience_data_list.append(get_output_for_row(g, discharge_id))\n",
    "        \n",
    "stop_time = time.perf_counter()\n",
    "print(f\"It took {stop_time - start_time} seconds or {(stop_time - start_time) / 60} minutes to create graphs\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discharge_id</th>\n",
       "      <th>avg_clust</th>\n",
       "      <th>cumulative_experience</th>\n",
       "      <th>avg_cumulative_experience</th>\n",
       "      <th>team_edge_size</th>\n",
       "      <th>team_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.677976</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discharge_id  avg_clust  cumulative_experience  avg_cumulative_experience  \\\n",
       "0             6   0.677976                    6.0                        1.0   \n",
       "\n",
       "   team_edge_size  team_size  \n",
       "0              15          6  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['discharge_id',\n",
    "        'avg_clust',\n",
    "        'cumulative_experience',\n",
    "        'avg_cumulative_experience',\n",
    "        'team_edge_size',\n",
    "        'team_size']\n",
    "\n",
    "# experience_df = pd.DataFrame(experience_data_list, columns=columns).drop_duplicates()\n",
    "experience_df = pd.DataFrame(experience_data_list, columns=columns)\n",
    "experience_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Albert RomeroMargie Meyer', ('Albert Romero', 'Margie Meyer'), Timestamp('2019-04-15 00:00:00'))\n",
      "('Albert RomeroEvan Frazier', ('Albert Romero', 'Evan Frazier'), Timestamp('2019-04-15 00:00:00'))\n",
      "('Albert RomeroMyrtle George', ('Albert Romero', 'Myrtle George'), Timestamp('2019-04-15 00:00:00'))\n",
      "('Albert RomeroVictoria Washington', ('Albert Romero', 'Victoria Washington'), Timestamp('2019-04-15 00:00:00'))\n",
      "('Albert RomeroBrad Palmer', ('Albert Romero', 'Brad Palmer'), Timestamp('2019-04-15 00:00:00'))\n",
      "('Albert RomeroNeil Mitchell', ('Albert Romero', 'Neil Mitchell'), Timestamp('2019-04-15 00:00:00'))\n",
      "('Margie MeyerMyrtle George', ('Margie Meyer', 'Myrtle George'), Timestamp('2019-04-15 00:00:00'))\n",
      "('Margie MeyerVictoria Washington', ('Margie Meyer', 'Victoria Washington'), Timestamp('2019-04-15 00:00:00'))\n",
      "('Margie MeyerNeil Mitchell', ('Margie Meyer', 'Neil Mitchell'), Timestamp('2019-04-15 00:00:00'))\n",
      "('Evan FrazierMargie Meyer', ('Evan Frazier', 'Margie Meyer'), Timestamp('2019-04-15 00:00:00'))\n",
      "('Evan FrazierMyrtle George', ('Evan Frazier', 'Myrtle George'), Timestamp('2019-04-15 00:00:00'))\n",
      "('Evan FrazierVictoria Washington', ('Evan Frazier', 'Victoria Washington'), Timestamp('2019-04-15 00:00:00'))\n",
      "('Evan FrazierNeil Mitchell', ('Evan Frazier', 'Neil Mitchell'), Timestamp('2019-04-15 00:00:00'))\n",
      "('Myrtle GeorgeVictoria Washington', ('Myrtle George', 'Victoria Washington'), Timestamp('2019-04-15 00:00:00'))\n",
      "('Myrtle GeorgeNeil Mitchell', ('Myrtle George', 'Neil Mitchell'), Timestamp('2019-04-15 00:00:00'))\n",
      "('Brad PalmerMargie Meyer', ('Brad Palmer', 'Margie Meyer'), Timestamp('2019-04-15 00:00:00'))\n",
      "('Brad PalmerEvan Frazier', ('Brad Palmer', 'Evan Frazier'), Timestamp('2019-04-15 00:00:00'))\n",
      "('Brad PalmerMyrtle George', ('Brad Palmer', 'Myrtle George'), Timestamp('2019-04-15 00:00:00'))\n",
      "('Brad PalmerVictoria Washington', ('Brad Palmer', 'Victoria Washington'), Timestamp('2019-04-15 00:00:00'))\n",
      "('Brad PalmerNeil Mitchell', ('Brad Palmer', 'Neil Mitchell'), Timestamp('2019-04-15 00:00:00'))\n",
      "('Neil MitchellVictoria Washington', ('Neil Mitchell', 'Victoria Washington'), Timestamp('2019-04-15 00:00:00'))\n"
     ]
    }
   ],
   "source": [
    "for discharge_id, edges in discharge_id_to_edges_dict.items(): \n",
    "    for e in edges:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This code does not work but playing around with an easy API for the library'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''This code does not work but playing around with an easy API for the library'''\n",
    "\n",
    "# column_names = {\n",
    "#     \"visit_id\": \"discharge_id\",\n",
    "#     \"admission_date\": \"arrive_date\",\n",
    "#     \"note_author\": \"dr\",\n",
    "#     \"note_date\": \"date\"\n",
    "# }\n",
    "\n",
    "# EXPERIENCE_WINDOW = 90\n",
    "# TEAM_WINDOW = 2\n",
    "\n",
    "# study = TeamWorkStudy(notes_csv_file, EXPERIENCE_WINDOW,TEAM_WINDOW, column_names=column_names)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
