{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from itertools import combinations \n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from math import comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.2346821998944506 seconds or 0.003911369998240844 minutes to read in data and modify table\n",
      "      id     dr       date    patient arrive_date discharge_date  disposition  \\\n",
      "2559  15  dr212 2020-03-16  patient16  2020-03-09     2020-03-16            0   \n",
      "2533  15  dr189 2020-03-13  patient16  2020-03-09     2020-03-16            0   \n",
      "2534  15  dr189 2020-03-12  patient16  2020-03-09     2020-03-16            0   \n",
      "2540  15  dr193 2020-03-15  patient16  2020-03-09     2020-03-16            0   \n",
      "2545  15   dr28 2020-03-11  patient16  2020-03-09     2020-03-16            0   \n",
      "\n",
      "      age norm_arrive_date norm_note_date  is_in_team  \n",
      "2559   65       2020-03-09     2020-03-16       False  \n",
      "2533   65       2020-03-09     2020-03-13       False  \n",
      "2534   65       2020-03-09     2020-03-12       False  \n",
      "2540   65       2020-03-09     2020-03-15       False  \n",
      "2545   65       2020-03-09     2020-03-11        True  \n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "\n",
    "# discharges_test_file = '../data/discharges_test.csv'\n",
    "# notes_test_file = '../data/notes_test.csv'\n",
    "\n",
    "discharges_test_file = '../data/discharges_w_disposition_abdul_test.csv'\n",
    "notes_test_file = '../data/notes_w_disposition_abdul_test.csv'\n",
    "\n",
    "discharge_table = pd.read_csv(discharges_test_file, parse_dates=['arrive_date','discharge_date'])\n",
    "notes_table = pd.read_csv(notes_test_file, parse_dates=['date'])\n",
    "notes_table.rename(columns = {'discharge_id':'id'}, inplace = True)\n",
    "\n",
    "# authors who wrote notes within 48 hours of arrival date are in index team for that patient\n",
    "INDEX_DELTA = np.timedelta64(2, 'D')\n",
    "# notes written within previous 90 days are considered when calculating collaborative experience\n",
    "TEAMWORK_DELTA = np.timedelta64(90, 'D')\n",
    "\n",
    "# match in admission datetime indexing on visit id from discharge table\n",
    "notes_table = notes_table.merge(discharge_table, on='id', how='right')\n",
    "\n",
    "# create new column for normalized date by ignoring time of day\n",
    "notes_table['norm_arrive_date'] = notes_table['arrive_date'].astype('datetime64[D]')\n",
    "notes_table['norm_note_date'] = notes_table['date'].astype('datetime64[D]')\n",
    "\n",
    "notes_table.drop_duplicates(['norm_note_date','dr','id'], keep=\"first\", inplace=True)\n",
    "\n",
    "notes_table.sort_values('arrive_date', inplace=True)\n",
    "FIRST_DATE = notes_table['arrive_date'].iloc[0]\n",
    "\n",
    "# add indicator column for whether the note author is in the index team\n",
    "notes_table['is_in_team'] = notes_table[\"date\"] - notes_table[\"arrive_date\"] <= INDEX_DELTA\n",
    "\n",
    "stop_time = time.perf_counter()\n",
    "print(f\"It took {stop_time - start_time} seconds or {(stop_time - start_time) / 60} minutes to read in data and modify table\")   \n",
    "\n",
    "print(notes_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.3169557999353856 seconds or 0.00528259666558976 minutes to self join and get edges table\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "\n",
    "# do self join on discharge id and normalized note date to get table of edges\n",
    "edges_table = notes_table.merge(notes_table[['dr','id','is_in_team','norm_note_date']], how='inner', on=['id','norm_note_date'])\n",
    "# remove edges with the same name twice or with authors in reverse order\n",
    "edges_table = edges_table[edges_table['dr_x'] < edges_table['dr_y']]\n",
    "edges_table['edge'] = edges_table['dr_x'] + edges_table['dr_y']\n",
    "\n",
    "# might be able to remove this line, need to discuss\n",
    "edges_table['is_in_team'] = edges_table['is_in_team_x'] & edges_table['is_in_team_y']\n",
    "# add column indicating whether there are 90 days prior to arrive date. if not, don't count as index team\n",
    "edges_table['is_after_delta'] = edges_table[\"arrive_date\"] > (FIRST_DATE + TEAMWORK_DELTA)\n",
    "\n",
    "stop_time = time.perf_counter()\n",
    "print(f\"It took {stop_time - start_time} seconds or {(stop_time - start_time) / 60} minutes to self join and get edges table\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 1.128571099950932 seconds or 0.018809518332515533 minutes to self join and get edges table\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "\n",
    "# do self join on discharge id get table of team edges\n",
    "team_table = notes_table.merge(notes_table[['dr','id','is_in_team','norm_note_date']], how='inner', on='id')\n",
    "# remove edges with the same name twice or with authors in reverse order\n",
    "team_table = team_table[team_table['dr_x'] < team_table['dr_y']]\n",
    "team_table['edge'] = team_table['dr_x'] + team_table['dr_y']\n",
    "\n",
    "# might be able to remove this line, need to discuss\n",
    "team_table['is_in_team'] = team_table['is_in_team_x'] & team_table['is_in_team_y']\n",
    "# add column indicating whether there are 90 days prior to arrive date. if not, don't count as index team\n",
    "team_table['is_after_delta'] = team_table[\"arrive_date\"] > (FIRST_DATE + TEAMWORK_DELTA)\n",
    "\n",
    "team_table = team_table[team_table['is_in_team'] & team_table['is_after_delta']]\n",
    "\n",
    "stop_time = time.perf_counter()\n",
    "print(f\"It took {stop_time - start_time} seconds or {(stop_time - start_time) / 60} minutes to self join and get edges table\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_for_row(g, visit_id, team):\n",
    "    data = {}\n",
    "    data['discharge_id'] = visit_id\n",
    "    \n",
    "    ''' Clustering coefficient of all nodes (in a dictionary) '''\n",
    "    clustering_coefficient = nx.clustering(g, weight='weight')\n",
    "    \n",
    "    ''' Average clustering coefficient with divide-by-zero check '''\n",
    "    clust_sum = sum(clustering_coefficient.values())\n",
    "    clust_len = len(clustering_coefficient)\n",
    "        \n",
    "    data['avg_clust'] = clust_sum / clust_len if clust_len > 0 else 0 \n",
    "    \n",
    "    data['sum_clust'] = clust_sum\n",
    "    data['team_size'] = len(team)\n",
    "    potential_edges = comb(len(team),2)\n",
    "    data['potential_edges'] = potential_edges\n",
    "    data['team_edge_size'] = g.number_of_edges()\n",
    "    \n",
    "    experience = g.size(weight='weight') #Experience as sum of weights\n",
    "    data['cumulative_experience'] = experience - data['team_edge_size']\n",
    "    data['avg_cumulative_experience'] = data['cumulative_experience'] / potential_edges if data['team_size'] > 0 else 0\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/std.py:699: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "Dictionary Progress Bar!: 100%|██████████| 122390/122390 [00:04<00:00, 27791.97it/s]\n",
      "Dictionary Progress Bar!: 100%|██████████| 53951/53951 [00:02<00:00, 19479.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 7.185759199899621 seconds or 0.11976265333166035 minutes to build dictionaries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# map discharge id to list of edges\n",
    "discharge_id_to_edges_dict = dict()\n",
    "# map edge to list of dates when note authors collaborated\n",
    "edge_to_date_dict = dict()\n",
    "# map discharge id to list of team members\n",
    "discharge_id_to_team_dict = dict()\n",
    "\n",
    "def add_to_team_dict(edge_record):\n",
    "    edge_tup = (edge_record['dr_x'], edge_record['dr_y'])\n",
    "    # store edge, individual note author names, and arrive date in list item\n",
    "    edge_list_item = (edge_record['edge'], edge_tup, edge_record['norm_arrive_date'])\n",
    "    discharge_id_to_edges_dict.setdefault(edge_record['id'],[]).append(edge_list_item)\n",
    "    discharge_id_to_team_dict.setdefault(edge_record['id'],set()).update(edge_tup)\n",
    "\n",
    "def add_edge_to_dict(edge_record):\n",
    "    edge_to_date_dict.setdefault(edge_record['edge'],[]).append(edge_record['norm_note_date'])\n",
    "    \n",
    "tqdm.pandas(desc=\"Dictionary Progress Bar!\")\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "# edges_table.apply(add_edge_to_dict, axis='columns')\n",
    "\n",
    "# team_table.apply(add_to_team_dict, axis='columns')\n",
    "\n",
    "edges_table.progress_apply(add_edge_to_dict, axis='columns')\n",
    "\n",
    "team_table.progress_apply(add_to_team_dict, axis='columns')\n",
    "    \n",
    "stop_time = time.perf_counter()\n",
    "print(f\"It took {stop_time - start_time} seconds or {(stop_time - start_time) / 60} minutes to build dictionaries\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 541/541 [00:01<00:00, 384.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 1.4093690000008792 seconds or 0.023489483333347987 minutes to create graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "experience_data_list = []\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "for discharge_id, edge_items in tqdm(discharge_id_to_edges_dict.items()):\n",
    "    edge_list = []\n",
    "    for edge_item in edge_items:\n",
    "        edge = edge_item[0]\n",
    "        if edge not in edge_to_date_dict: continue\n",
    "        (dr_x,dr_y) = edge_item[1]\n",
    "        arrive_date = edge_item[2]\n",
    "        weight = len([note_day for note_day in edge_to_date_dict[edge] \n",
    "                      if note_day < arrive_date and note_day >= arrive_date - TEAMWORK_DELTA])\n",
    "        if(weight < 1): continue \n",
    "        edge_list.append({'source':dr_x,'target':dr_y,'weight':weight})\n",
    "    edge_df = pd.DataFrame(edge_list, columns = ['source', 'target', 'weight'])\n",
    "    g = nx.from_pandas_edgelist(edge_df, source='source', target='target',edge_attr='weight')\n",
    "    team = discharge_id_to_team_dict[discharge_id]\n",
    "    experience_data_list.append(get_output_for_row(g, discharge_id, team))\n",
    "        \n",
    "stop_time = time.perf_counter()\n",
    "print(f\"It took {stop_time - start_time} seconds or {(stop_time - start_time) / 60} minutes to create graphs\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discharge_id</th>\n",
       "      <th>avg_clust</th>\n",
       "      <th>cumulative_experience</th>\n",
       "      <th>avg_cumulative_experience</th>\n",
       "      <th>team_edge_size</th>\n",
       "      <th>team_size</th>\n",
       "      <th>potential_edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>208</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>241</td>\n",
       "      <td>0.401690</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>74</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>283</td>\n",
       "      <td>0.342668</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>378</td>\n",
       "      <td>0.365958</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    discharge_id  avg_clust  cumulative_experience  avg_cumulative_experience  \\\n",
       "0             40   0.000000                    3.0                   0.107143   \n",
       "1            208   0.333333                   27.0                   1.285714   \n",
       "2             60   0.000000                   20.0                   0.444444   \n",
       "3             28   0.000000                    6.0                   0.285714   \n",
       "4            158   0.000000                    6.0                   0.400000   \n",
       "5            285   0.000000                   12.0                   0.428571   \n",
       "6            338   0.000000                   10.0                   0.666667   \n",
       "7            241   0.401690                   18.0                   0.500000   \n",
       "8            457   0.000000                    6.0                   0.400000   \n",
       "9            105   0.000000                   23.0                   0.821429   \n",
       "10            74   0.000000                   11.0                   0.305556   \n",
       "11           140   0.000000                    6.0                   0.133333   \n",
       "12           283   0.342668                   29.0                   0.644444   \n",
       "13           292   0.000000                   21.0                   1.000000   \n",
       "14           637   0.000000                    6.0                   0.166667   \n",
       "15           679   0.000000                   17.0                   0.472222   \n",
       "16           415   0.000000                    5.0                   0.178571   \n",
       "17           585   0.000000                   29.0                   0.805556   \n",
       "18           651   0.000000                    2.0                   0.133333   \n",
       "19           378   0.365958                   22.0                   0.785714   \n",
       "\n",
       "    team_edge_size  team_size  potential_edges  \n",
       "0                1          8               28  \n",
       "1                5          7               21  \n",
       "2                4         10               45  \n",
       "3                1          7               21  \n",
       "4                1          6               15  \n",
       "5                2          8               28  \n",
       "6                2          6               15  \n",
       "7                4          9               36  \n",
       "8                1          6               15  \n",
       "9                4          8               28  \n",
       "10               2          9               36  \n",
       "11               1         10               45  \n",
       "12               6         10               45  \n",
       "13               3          7               21  \n",
       "14               1          9               36  \n",
       "15               3          9               36  \n",
       "16               1          8               28  \n",
       "17               6          9               36  \n",
       "18               1          6               15  \n",
       "19               5          8               28  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['discharge_id',\n",
    "        'avg_clust',\n",
    "        'cumulative_experience',\n",
    "        'avg_cumulative_experience',\n",
    "        'team_edge_size',\n",
    "           'team_size',\n",
    "           'potential_edges'\n",
    "          ]\n",
    "\n",
    "# experience_df = pd.DataFrame(experience_data_list, columns=columns).drop_duplicates()\n",
    "experience_df = pd.DataFrame(experience_data_list, columns=columns)\n",
    "experience_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This code does not work but playing around with an easy API for the library'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''This code does not work but playing around with an easy API for the library'''\n",
    "\n",
    "# column_names = {\n",
    "#     \"visit_id\": \"discharge_id\",\n",
    "#     \"admission_date\": \"arrive_date\",\n",
    "#     \"note_author\": \"dr\",\n",
    "#     \"note_date\": \"date\"\n",
    "# }\n",
    "\n",
    "# EXPERIENCE_WINDOW = 90\n",
    "# TEAM_WINDOW = 2\n",
    "\n",
    "# study = TeamWorkStudy(notes_csv_file, EXPERIENCE_WINDOW,TEAM_WINDOW, column_names=column_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5, 8}\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myset = set([1,2,3])\n",
    "myset.add(1)\n",
    "myset.add(4)\n",
    "myset.update((2,5,8))\n",
    "print(myset)\n",
    "print(len(myset))\n",
    "\n",
    "from math import comb\n",
    "comb(4,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date' 'value' 'another' 'another_column']\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.DataFrame({'date': ['3/10/2000', '3/11/2000', '3/12/2000'],\n",
    "                   'value': [2, 3, 4],\n",
    "                       'another': [6,7,8]})\n",
    "def add_column(df):\n",
    "    df['another_column'] = [7,8,9]\n",
    "add_column(test_df)\n",
    "print(test_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "{1, 2, 3}\n",
      "1\n",
      "4\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = {'values':'value', 'datetime':'custdate'}\n",
    "defcols = {'datetime':'date','values':'value','hello':[1,2,3], 'goodbye':{1,2,3}}\n",
    "mycols = {**defcols,**cols}\n",
    "def take_params(**cols):\n",
    "    print(cols['hello'])\n",
    "take_params(**mycols)\n",
    "\n",
    "_,v,_,gb = [*mycols.values()]\n",
    "print(gb)  \n",
    "\n",
    "def print_val(v):\n",
    "    print(v)\n",
    "    \n",
    "list(map(print_val, [1,4,5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-05-04 00:08:24.345376 ForkPoolWorker-1 running for r := 18\n",
      "2021-05-04 00:08:24.345576 ForkPoolWorker-2 running for r := 18\n",
      "2021-05-04 00:08:24.345897 ForkPoolWorker-3 running for r := 13\n",
      "2021-05-04 00:08:24.346157 ForkPoolWorker-4 running for r := 18\n",
      "\n",
      "\n",
      "\n",
      "cpu count: 8\n",
      "2021-05-04 00:08:24.341747 MainProcess waiting\n",
      "2021-05-04 00:08:31.836306 ForkPoolWorker-3 exiting with sum of 541668454169537501716\n",
      "in callback: 541668454169537501716\n",
      "2021-05-04 00:08:34.234262 ForkPoolWorker-2 exiting with sum of 750003600008175006936\n",
      "2021-05-04 00:08:34.343296 ForkPoolWorker-1 exiting with sum of 750003600008175006936\n",
      "in callback: 750003600008175006936\n",
      "in callback: 750003600008175006936\n",
      "2021-05-04 00:08:34.471361 ForkPoolWorker-4 exiting with sum of 750003600008175006936\n",
      "in callback: 750003600008175006936\n",
      "2021-05-04 00:08:34.485519 MainProcess out of with block\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool, Process, connection, current_process, cpu_count\n",
    "from random import randint\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def run(i):\n",
    "    sleep_time = randint(2,10)\n",
    "    sleep(sleep_time)\n",
    "    print(f\"{datetime.now()} {current_process().name} exiting with arg {i} after sleeping for {sleep_time}\")\n",
    "\n",
    "def cpu_bound(numbers, r):\n",
    "    print(f\"\\n{datetime.now()} {current_process().name} running for r := {r}\")\n",
    "    thesum = sum(sum(i * i for i in range(number)) for number in numbers)\n",
    "    print(f\"{datetime.now()} {current_process().name} exiting with sum of {thesum}\")\n",
    "    return thesum\n",
    "\n",
    "def get_numbers(r):\n",
    "    return [5_000_000 + i for i in range(r)]\n",
    "\n",
    "def print_res(res):\n",
    "    print(f'in callback: {res}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(cpu_count()) as pool:\n",
    "        print(f'cpu count: {cpu_count()}')\n",
    "#         pool = [Process(target=cpu_bound,args=(get_numbers(r := randint(10,20)), r)) for _ in range(4)]\n",
    "        print(f\"{datetime.now()} {current_process().name} waiting\")\n",
    "        multiple_results = [pool.apply_async(cpu_bound, args=(get_numbers(r := randint(10,20)), r), callback=print_res) for _ in range(4)]\n",
    "        [res.get() for res in multiple_results]\n",
    "\n",
    "    print(f\"{datetime.now()} {current_process().name} out of with block\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
